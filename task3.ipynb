{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5wvtD8KEHix",
        "outputId": "2801c44c-cde9-40eb-f1dd-082abf1a861c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (2000, 8)\n",
            "Missing values:\n",
            " CustomerID                 0\n",
            "Gender                     0\n",
            "Age                        0\n",
            "Annual Income ($)          0\n",
            "Spending Score (1-100)     0\n",
            "Profession                35\n",
            "Work Experience            0\n",
            "Family Size                0\n",
            "dtype: int64\n",
            "Optimal k (by silhouette): 2\n",
            "Saved clustered dataset -> clustering_outputs/customers_clustered.csv\n",
            "\n",
            "=== Cluster Recommendations ===\n",
            "Cluster 0: Moderate spender, High income, Older segment\n",
            "Cluster 1: Moderate spender\n",
            "\n",
            "Suggested actions:\n",
            "- High spenders → Target with loyalty programs & premium product offers.\n",
            "- Low spenders but high income → Target with exclusive promotions to increase spending.\n",
            "- Young high spenders → Push trending/new products.\n",
            "- Older moderate spenders → Focus on value deals and long-term memberships.\n",
            "\n",
            "All visuals and CSVs saved to folder: clustering_outputs\n"
          ]
        }
      ],
      "source": [
        "# customer_clustering_with_recommendations.py\n",
        "# pip install pandas numpy scikit-learn matplotlib seaborn\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# ======================\n",
        "# 1. Load Dataset\n",
        "# ======================\n",
        "INPUT_CSV = \"Customers (1).csv\"  # change to your CSV file path\n",
        "OUTDIR = \"clustering_outputs\"\n",
        "os.makedirs(OUTDIR, exist_ok=True)\n",
        "\n",
        "df = pd.read_csv(\"/content/Customers.csv\")\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Missing values:\\n\", df.isna().sum())\n",
        "\n",
        "# ======================\n",
        "# 2. Data Preprocessing\n",
        "# ======================\n",
        "num_df = df.select_dtypes(include=[np.number]).copy()\n",
        "\n",
        "# Drop constant columns\n",
        "constant_cols = [c for c in num_df.columns if num_df[c].nunique(dropna=True) <= 1]\n",
        "if constant_cols:\n",
        "    num_df = num_df.drop(columns=constant_cols)\n",
        "\n",
        "# Impute missing numeric values with median\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "X_imputed = imputer.fit_transform(num_df)\n",
        "\n",
        "# Standardize\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_imputed)\n",
        "\n",
        "feature_names = num_df.columns.tolist()\n",
        "\n",
        "# ======================\n",
        "# 3. Determine Optimal k\n",
        "# ======================\n",
        "K_MAX = 10\n",
        "wcss = []\n",
        "sil_scores = {}\n",
        "for k in range(1, K_MAX + 1):\n",
        "    km = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
        "    km.fit(X_scaled)\n",
        "    wcss.append(km.inertia_)\n",
        "    if k >= 2:\n",
        "        sil_scores[k] = silhouette_score(X_scaled, km.labels_)\n",
        "\n",
        "optimal_k = max(sil_scores, key=sil_scores.get)\n",
        "print(f\"Optimal k (by silhouette): {optimal_k}\")\n",
        "\n",
        "# Plot Elbow Method\n",
        "plt.figure()\n",
        "plt.plot(range(1, K_MAX + 1), wcss, marker=\"o\")\n",
        "plt.title(\"Elbow Method: WCSS vs k\")\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"WCSS\")\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTDIR, \"elbow_wcss.png\"), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# ======================\n",
        "# 4. Final Clustering\n",
        "# ======================\n",
        "final_km = KMeans(n_clusters=optimal_k, n_init=10, random_state=42)\n",
        "cluster_labels = final_km.fit_predict(X_scaled)\n",
        "df[\"cluster\"] = cluster_labels\n",
        "\n",
        "# Save clustered dataset\n",
        "clustered_csv = os.path.join(OUTDIR, \"customers_clustered.csv\")\n",
        "df.to_csv(clustered_csv, index=False)\n",
        "print(\"Saved clustered dataset ->\", clustered_csv)\n",
        "\n",
        "# ======================\n",
        "# 5. Visualizations\n",
        "# ======================\n",
        "\n",
        "# PCA Scatter Plot\n",
        "pca = PCA(n_components=2, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "centers_pca = pca.transform(final_km.cluster_centers_)\n",
        "\n",
        "plt.figure()\n",
        "for cl in np.unique(cluster_labels):\n",
        "    idx = cluster_labels == cl\n",
        "    plt.scatter(X_pca[idx, 0], X_pca[idx, 1], label=f\"Cluster {cl}\", alpha=0.8)\n",
        "plt.scatter(centers_pca[:, 0], centers_pca[:, 1], marker=\"X\", s=200, color=\"black\", label=\"Centroids\")\n",
        "plt.title(f\"PCA Scatter Plot (k={optimal_k})\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTDIR, \"pca_scatter.png\"), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Heatmap of Cluster Centroids (Original Scale)\n",
        "centers_original = scaler.inverse_transform(final_km.cluster_centers_)\n",
        "centroids_df = pd.DataFrame(centers_original, columns=feature_names)\n",
        "centroids_df.index = [f\"Cluster {i}\" for i in range(optimal_k)]\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(centroids_df, annot=True, fmt=\".1f\", cmap=\"coolwarm\")\n",
        "plt.title(\"Cluster Centroids (Original Scale)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(OUTDIR, \"centroids_heatmap.png\"), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Optional Pair Plots (Top 3 high-variance features)\n",
        "variances = X_imputed.var(axis=0)\n",
        "top_features = pd.Series(variances, index=feature_names).nlargest(3).index.tolist()\n",
        "sns.pairplot(pd.DataFrame(X_imputed, columns=feature_names)[top_features]\n",
        "             .assign(cluster=cluster_labels), hue=\"cluster\", diag_kind=\"kde\", palette=\"tab10\")\n",
        "plt.savefig(os.path.join(OUTDIR, \"pair_plots.png\"), dpi=150)\n",
        "plt.close()\n",
        "\n",
        "# Save centroids to CSV\n",
        "centroids_csv = os.path.join(OUTDIR, \"cluster_centroids_original_scale.csv\")\n",
        "centroids_df.to_csv(centroids_csv)\n",
        "\n",
        "# ======================\n",
        "# 6. Recommendations\n",
        "# ======================\n",
        "print(\"\\n=== Cluster Recommendations ===\")\n",
        "for i, row in centroids_df.iterrows():\n",
        "    age = row.get(\"Age\", None)\n",
        "    income = row.get(\"Annual Income ($)\", None)\n",
        "    spend = row.get(\"Spending Score (1-100)\", None)\n",
        "\n",
        "    desc = []\n",
        "    if spend is not None:\n",
        "        if spend > 70:\n",
        "            desc.append(\"High spender\")\n",
        "        elif spend < 40:\n",
        "            desc.append(\"Low spender\")\n",
        "        else:\n",
        "            desc.append(\"Moderate spender\")\n",
        "    if income is not None:\n",
        "        if income > 80_000:\n",
        "            desc.append(\"High income\")\n",
        "        elif income < 40_000:\n",
        "            desc.append(\"Low income\")\n",
        "    if age is not None:\n",
        "        if age < 30:\n",
        "            desc.append(\"Young segment\")\n",
        "        elif age > 50:\n",
        "            desc.append(\"Older segment\")\n",
        "\n",
        "    print(f\"{i}: {', '.join(desc)}\")\n",
        "\n",
        "print(\"\\nSuggested actions:\")\n",
        "print(\"- High spenders → Target with loyalty programs & premium product offers.\")\n",
        "print(\"- Low spenders but high income → Target with exclusive promotions to increase spending.\")\n",
        "print(\"- Young high spenders → Push trending/new products.\")\n",
        "print(\"- Older moderate spenders → Focus on value deals and long-term memberships.\")\n",
        "\n",
        "print(f\"\\nAll visuals and CSVs saved to folder: {OUTDIR}\")\n"
      ]
    }
  ]
}